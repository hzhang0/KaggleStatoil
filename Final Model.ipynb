{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/haoran/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten, AveragePooling2D, Add, Activation, BatchNormalization, Concatenate, Dropout\n",
    "from keras.layers import Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('data/train/processed/train.json')\n",
    "test = pd.read_json('data/test/processed/test.json')\n",
    "train['band_1'] = train['band_1'].apply(lambda x: np.reshape(x, [75,75]))\n",
    "train['band_2'] = train['band_2'].apply(lambda x: np.reshape(x, [75,75]))\n",
    "train['inc_angle'] = pd.to_numeric(train['inc_angle'], errors = 'coerce')\n",
    "train['inc_angle'] = train['inc_angle'].fillna(value = train['inc_angle'].mean())\n",
    "\n",
    "dataInput = []\n",
    "for i in train.index:\n",
    "    dataInput.append(np.stack([train.loc[i]['band_1'], train.loc[i]['band_2']], axis = -1))\n",
    "dataInput = np.array(dataInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createGenerator( X, I, Y):\n",
    "    while True:\n",
    "        idx = np.random.permutation( X.shape[0])\n",
    "        datagen = image.ImageDataGenerator( \n",
    "                                            rotation_range=20,\n",
    "                                            height_shift_range=0.1,                                           \n",
    "                                            horizontal_flip = True,\n",
    "                                           vertical_flip = True, \n",
    "                                           width_shift_range=0.1,\n",
    "                                            fill_mode='wrap',\n",
    "                                          )\n",
    "      \n",
    "\n",
    "        batches = datagen.flow( X[idx], Y[idx], batch_size=64, shuffle=False)\n",
    "        idx0 = 0\n",
    "        for batch in batches:\n",
    "            idx1 = idx0 + batch[0].shape[0]\n",
    "\n",
    "            yield [batch[0], I[ idx[ idx0:idx1 ] ]], batch[1]\n",
    "\n",
    "            idx0 = idx1\n",
    "            if idx1 >= X.shape[0]:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model1():\n",
    "    image_input = Input(shape = (75,75,2))\n",
    "    x = BatchNormalization(axis = -1, input_shape= [75,75,2])(image_input)\n",
    "    #CNN 0\n",
    "    x = Conv2D(filters = 32, kernel_size = (3,3), activation='relu')(x)\n",
    "    x = BatchNormalization(axis = -1)(x) \n",
    "    x = MaxPooling2D((2,2), strides = (1,1))(x)\n",
    "\n",
    "    #CNN 1\n",
    "    x = Conv2D(filters = 64, kernel_size = (3,3), activation='relu')(x)\n",
    "    x = BatchNormalization(axis = -1)(x) \n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "\n",
    "    #CNN 2\n",
    "    x = Conv2D(filters = 128, kernel_size = (3,3), activation='relu')(x)\n",
    "    x = BatchNormalization(axis = -1)(x) \n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "\n",
    "    #CNN 3\n",
    "    x = Conv2D(filters = 128, kernel_size = (3,3), activation='relu')(x)\n",
    "    x = BatchNormalization(axis = -1)(x) \n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "\n",
    "    #CNN 4\n",
    "    x = Conv2D(filters = 64, kernel_size = (3,3), activation='relu')(x)\n",
    "    x = BatchNormalization(axis = -1)(x) \n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    inc_input = Input(shape = (1,)) #incidence angle\n",
    "    y = BatchNormalization(axis = -1)(inc_input)\n",
    "    x = Concatenate()([x,y])\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)    \n",
    "    model = Model(inputs = [image_input, inc_input], outputs= x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, f, filters):\n",
    "    f1,f2,f3 = filters\n",
    "    x = Conv2D(f1, (1,1))(input_tensor)\n",
    "    x = BatchNormalization(axis = -1)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(f2, f, padding = 'same')(x)\n",
    "    x = BatchNormalization(axis = -1)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(f3, (1,1))(x)\n",
    "    x = BatchNormalization(axis = -1)(x)\n",
    "    \n",
    "    x = Add()([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, f, filters, strides = (2,2)):\n",
    "    f1,f2,f3 = filters\n",
    "    x = Conv2D(f1, (1,1), strides = strides)(input_tensor)\n",
    "    x = BatchNormalization(axis = -1)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(f2, f, padding = 'same')(x)\n",
    "    x = BatchNormalization(axis = -1)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(f3, (1,1))(x)\n",
    "    x = BatchNormalization(axis = -1)(x)\n",
    "    \n",
    "    shortcut = Conv2D(f3, (1,1), strides = strides)(input_tensor)\n",
    "    shortcut = BatchNormalization(axis = -1)(shortcut)\n",
    "    \n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def model2():\n",
    "    image_input = Input(shape = (75,75,2))\n",
    "    x = BatchNormalization(axis = -1, input_shape= [75,75,2])(image_input)\n",
    "    x = Conv2D(filters = 32, kernel_size = (3,3), activation='relu')(x)\n",
    "    x = BatchNormalization(axis = -1)(x) \n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256])\n",
    "    x = identity_block(x, 3, [64, 64, 256])\n",
    "    x = identity_block(x, 3, [64, 64, 256])\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512])\n",
    "    x = identity_block(x, 3, [128, 128, 512])\n",
    "    x = identity_block(x, 3, [128, 128, 512])\n",
    "    x = identity_block(x, 3, [128, 128, 512])\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024])\n",
    "    x = identity_block(x, 3, [256, 256, 1024])\n",
    "    x = identity_block(x, 3, [256, 256, 1024])\n",
    "    #x = identity_block(x, 3, [256, 256, 1024])\n",
    "    #x = identity_block(x, 3, [256, 256, 1024])\n",
    "    #x = identity_block(x, 3, [256, 256, 1024])\n",
    "\n",
    "    # x = conv_block(x, 3, [512, 512, 2048])\n",
    "    # x = identity_block(x, 3, [512, 512, 2048])\n",
    "    # x = identity_block(x, 3, [512, 512, 2048])\n",
    "\n",
    "    x = AveragePooling2D((5,5))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    inc_input = Input(shape = (1,)) #incidence angle\n",
    "    y = BatchNormalization(axis = -1)(inc_input)\n",
    "    x = Concatenate()([x,y])\n",
    "    # x = Dense(512, activation='relu')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs = [image_input, inc_input], outputs= x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainModel(model, counter):\n",
    "    model.compile(Adam(1e-5), loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "    earlyStopping = EarlyStopping(monitor='loss', patience=50, verbose=0, mode='min')\n",
    "    reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=8, verbose=0, epsilon=1e-4, mode='min')\n",
    "    model.fit_generator(createGenerator(X = dataInput, I = train.inc_angle.values, Y = train.is_iceberg.values),\n",
    "                    steps_per_epoch = len(train)/64, epochs = 4, verbose = False)\n",
    "    K.set_value(model.optimizer.lr, 1e-2)\n",
    "    model.fit_generator(createGenerator(X = dataInput, I = train.inc_angle.values, Y = train.is_iceberg.values),\n",
    "                         callbacks=[earlyStopping, reduce_lr_loss],\n",
    "                       steps_per_epoch = len(train)/64, epochs = 300, verbose = False)\n",
    "    print('Finished training model', counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnnModels = [model1() for i in range(25)]\n",
    "resModels = [model2() for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haoran/anaconda3/lib/python3.6/site-packages/keras/preprocessing/image.py:855: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (1604, 75, 75, 2) (2 channels).\n",
      "  ' (' + str(self.x.shape[channels_axis]) + ' channels).')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training model 0\n",
      "Finished training model 1\n",
      "Finished training model 2\n",
      "Finished training model 3\n",
      "Finished training model 4\n",
      "Finished training model 5\n",
      "Finished training model 6\n",
      "Finished training model 7\n",
      "Finished training model 8\n",
      "Finished training model 9\n",
      "Finished training model 10\n",
      "Finished training model 11\n",
      "Finished training model 12\n",
      "Finished training model 13\n",
      "Finished training model 14\n",
      "Finished training model 15\n",
      "Finished training model 16\n",
      "Finished training model 17\n",
      "Finished training model 18\n",
      "Finished training model 19\n",
      "Finished training model 20\n",
      "Finished training model 21\n",
      "Finished training model 22\n",
      "Finished training model 23\n",
      "Finished training model 24\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(cnnModels)):\n",
    "    trainModel(cnnModels[i], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haoran/anaconda3/lib/python3.6/site-packages/keras/preprocessing/image.py:855: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (1604, 75, 75, 2) (2 channels).\n",
      "  ' (' + str(self.x.shape[channels_axis]) + ' channels).')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training model 0\n",
      "Finished training model 1\n",
      "Finished training model 2\n",
      "Finished training model 3\n",
      "Finished training model 4\n",
      "Finished training model 5\n",
      "Finished training model 6\n",
      "Finished training model 7\n",
      "Finished training model 8\n",
      "Finished training model 9\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(resModels)):\n",
    "    trainModel(resModels[i], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(cnnModels)):\n",
    "    cnnModels[i].save_weights(r'weights/ensembleFinal/cnn'+str(i)+'.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(resModels)):\n",
    "    resModels[i].save_weights(r'weights/ensembleFinal/res'+str(i)+'.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['band_1'] = test['band_1'].apply(lambda x: np.reshape(x, [75,75]))\n",
    "test['band_2'] = test['band_2'].apply(lambda x: np.reshape(x, [75,75]))\n",
    "dataTest = []\n",
    "for i in test.index:\n",
    "    dataTest.append(np.stack([test.loc[i]['band_1'], test.loc[i]['band_2']], axis = -1))\n",
    "dataTest = np.array(dataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = [i.predict([dataTest, test.inc_angle.values]) for i in cnnModels]\n",
    "predictions2 = [i.predict([dataTest, test.inc_angle.values]) for i in resModels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_avg1 = np.mean(list(zip(*predictions1)),axis = 1)\n",
    "pd.DataFrame({'id': test['id'], 'is_iceberg': np.ravel(pred_avg1)}).to_csv('data/answers/ensembleFinalCNNOnly.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_avg2 = np.mean(list(zip(*predictions2)),axis = 1)\n",
    "pd.DataFrame({'id': test['id'], 'is_iceberg': np.ravel(pred_avg2)}).to_csv('data/answers/ensembleFinalResOnly.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_avg3 = np.mean([pred_avg1, pred_avg2], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'id': test['id'], 'is_iceberg': np.ravel(pred_avg3)}).to_csv('data/answers/ensembleFinalCombined.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
